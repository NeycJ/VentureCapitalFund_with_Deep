{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Venture Funding with Deep Learning\n",
    "\n",
    "You work as a risk management associate at Alphabet Soup, a venture capital firm. Alphabet Soup’s business team receives many funding applications from startups every day. This team has asked you to help them create a model that predicts whether applicants will be successful if funded by Alphabet Soup.\n",
    "\n",
    "The business team has given you a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the years. With your knowledge of machine learning and neural networks, you decide to use the features in the provided dataset to create a binary classifier model that will predict whether an applicant will become a successful business. The CSV file contains a variety of information about these businesses, including whether or not they ultimately became successful.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "The steps for this challenge are broken out into the following sections:\n",
    "\n",
    "* Prepare the data for use on a neural network model.\n",
    "\n",
    "* Compile and evaluate a binary classification model using a neural network.\n",
    "\n",
    "* Optimize the neural network model.\n",
    "\n",
    "### Prepare the Data for Use on a Neural Network Model \n",
    "\n",
    "Using your knowledge of Pandas and scikit-learn’s `StandardScaler()`, preprocess the dataset so that you can use it to compile and evaluate the neural network model later.\n",
    "\n",
    "Open the starter code file, and complete the following data preparation steps:\n",
    "\n",
    "1. Read the `applicants_data.csv` file into a Pandas DataFrame. Review the DataFrame, looking for categorical variables that will need to be encoded, as well as columns that could eventually define your features and target variables.   \n",
    "\n",
    "2. Drop the “EIN” (Employer Identification Number) and “NAME” columns from the DataFrame, because they are not relevant to the binary classification model.\n",
    " \n",
    "3. Encode the dataset’s categorical variables using `OneHotEncoder`, and then place the encoded variables into a new DataFrame.\n",
    "\n",
    "4. Add the original DataFrame’s numerical variables to the DataFrame containing the encoded variables.\n",
    "\n",
    "> **Note** To complete this step, you will employ the Pandas `concat()` function that was introduced earlier in this course. \n",
    "\n",
    "5. Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “IS_SUCCESSFUL”. The remaining columns should define the features dataset. \n",
    "\n",
    "6. Split the features and target sets into training and testing datasets.\n",
    "\n",
    "7. Use scikit-learn's `StandardScaler` to scale the features data.\n",
    "\n",
    "### Compile and Evaluate a Binary Classification Model Using a Neural Network\n",
    "\n",
    "Use your knowledge of TensorFlow to design a binary classification deep neural network model. This model should use the dataset’s features to predict whether an Alphabet Soup&ndash;funded startup will be successful based on the features in the dataset. Consider the number of inputs before determining the number of layers that your model will contain or the number of neurons on each layer. Then, compile and fit your model. Finally, evaluate your binary classification model to calculate the model’s loss and accuracy. \n",
    " \n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
    "\n",
    "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n",
    "\n",
    "2. Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n",
    "\n",
    "> **Hint** When fitting the model, start with a small number of epochs, such as 20, 50, or 100.\n",
    "\n",
    "3. Evaluate the model using the test data to determine the model’s loss and accuracy.\n",
    "\n",
    "4. Save and export your model to an HDF5 file, and name the file `AlphabetSoup.h5`. \n",
    "\n",
    "### Optimize the Neural Network Model\n",
    "\n",
    "Using your knowledge of TensorFlow and Keras, optimize your model to improve the model's accuracy. Even if you do not successfully achieve a better accuracy, you'll need to demonstrate at least two attempts to optimize the model. You can include these attempts in your existing notebook. Or, you can make copies of the starter notebook in the same folder, rename them, and code each model optimization in a new notebook. \n",
    "\n",
    "> **Note** You will not lose points if your model does not achieve a high accuracy, as long as you make at least two attempts to optimize the model.\n",
    "\n",
    "To do so, complete the following steps:\n",
    "\n",
    "1. Define at least three new deep neural network models (the original plus 2 optimization attempts). With each, try to improve on your first model’s predictive accuracy.\n",
    "\n",
    "> **Rewind** Recall that perfect accuracy has a value of 1, so accuracy improves as its value moves closer to 1. To optimize your model for a predictive accuracy as close to 1 as possible, you can use any or all of the following techniques:\n",
    ">\n",
    "> * Adjust the input data by dropping different features columns to ensure that no variables or outliers confuse the model.\n",
    ">\n",
    "> * Add more neurons (nodes) to a hidden layer.\n",
    ">\n",
    "> * Add more hidden layers.\n",
    ">\n",
    "> * Use different activation functions for the hidden layers.\n",
    ">\n",
    "> * Add to or reduce the number of epochs in the training regimen.\n",
    "\n",
    "2. After finishing your models, display the accuracy scores achieved by each model, and compare the results.\n",
    "\n",
    "3. Save each of your models as an HDF5 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prepare the data to be used on a neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `applicants_data.csv` file into a Pandas DataFrame. Review the DataFrame, looking for categorical variables that will need to be encoded, as well as columns that could eventually define your features and target variables.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the applicants_data.csv file from the Resources folder into a Pandas DataFrame\n",
    "applicant_data_df = pd.read_csv('applicants_data.csv')\n",
    "\n",
    "# Review the DataFrame\n",
    "applicant_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   EIN                     34299 non-null  int64 \n",
      " 1   NAME                    34299 non-null  object\n",
      " 2   APPLICATION_TYPE        34299 non-null  object\n",
      " 3   AFFILIATION             34299 non-null  object\n",
      " 4   CLASSIFICATION          34299 non-null  object\n",
      " 5   USE_CASE                34299 non-null  object\n",
      " 6   ORGANIZATION            34299 non-null  object\n",
      " 7   STATUS                  34299 non-null  int64 \n",
      " 8   INCOME_AMT              34299 non-null  object\n",
      " 9   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
      " 10  ASK_AMT                 34299 non-null  int64 \n",
      " 11  IS_SUCCESSFUL           34299 non-null  int64 \n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Review the data types associated with the columns\n",
    "applicant_data_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Drop the “EIN” (Employer Identification Number) and “NAME” columns from the DataFrame, because they are not relevant to the binary classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'EIN' and 'NAME' columns from the DataFrame\n",
    "applicant_data_df = applicant_data_df.drop(columns = ['EIN', 'NAME'])\n",
    "\n",
    "# Review the DataFrame\n",
    "applicant_data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Encode the dataset’s categorical variables using `OneHotEncoder`, and then place the encoded variables into a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(applicant_data_df.dtypes[applicant_data_df.dtypes == 'object'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables  = ['APPLICATION_TYPE',\n",
    " 'AFFILIATION',\n",
    " 'CLASSIFICATION',\n",
    " 'USE_CASE',\n",
    " 'ORGANIZATION',\n",
    " 'INCOME_AMT',\n",
    " 'SPECIAL_CONSIDERATIONS']\n",
    "\n",
    "# Display the categorical variables list\n",
    "categorical_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "\n",
       "   ORGANIZATION  STATUS INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1          0                      N     5000   \n",
       "1  Co-operative       1     1-9999                      N   108590   \n",
       "2   Association       1          0                      N     5000   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applicant_data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   APPLICATION_TYPE        34299 non-null  object\n",
      " 1   AFFILIATION             34299 non-null  object\n",
      " 2   CLASSIFICATION          34299 non-null  object\n",
      " 3   USE_CASE                34299 non-null  object\n",
      " 4   ORGANIZATION            34299 non-null  object\n",
      " 5   STATUS                  34299 non-null  int64 \n",
      " 6   INCOME_AMT              34299 non-null  object\n",
      " 7   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
      " 8   ASK_AMT                 34299 non-null  int64 \n",
      " 9   IS_SUCCESSFUL           34299 non-null  int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "applicant_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse_output=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(applicant_data_df[categorical_variables])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>APPLICATION_TYPE_T25</th>\n",
       "      <th>APPLICATION_TYPE_T29</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  APPLICATION_TYPE_T13  \\\n",
       "0                   1.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  APPLICATION_TYPE_T17  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  APPLICATION_TYPE_T25  \\\n",
       "0                   0.0                  0.0                   0.0   \n",
       "1                   0.0                  0.0                   0.0   \n",
       "2                   0.0                  0.0                   0.0   \n",
       "3                   0.0                  0.0                   0.0   \n",
       "4                   0.0                  0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T29  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                   0.0  ...                0.0                     0.0   \n",
       "1                   0.0  ...                1.0                     0.0   \n",
       "2                   0.0  ...                0.0                     0.0   \n",
       "3                   0.0  ...                0.0                     1.0   \n",
       "4                   0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_data, columns = enc.get_feature_names_out(categorical_variables))\n",
    "\n",
    "# Review the DataFrame\n",
    "encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Add the original DataFrame’s numerical variables to the DataFrame containing the encoded variables.\n",
    "\n",
    "> **Note** To complete this step, you will employ the Pandas `concat()` function that was introduced earlier in this course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL\n",
       "0       1     5000              1\n",
       "1       1   108590              1\n",
       "2       1     5000              0\n",
       "3       1     6692              1\n",
       "4       1   142590              1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = applicant_data_df.drop(columns = categorical_variables)\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  \\\n",
       "0       1     5000              1                   1.0                   0.0   \n",
       "1       1   108590              1                   0.0                   0.0   \n",
       "2       1     5000              0                   0.0                   0.0   \n",
       "3       1     6692              1                   0.0                   0.0   \n",
       "4       1   142590              1                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T13  APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T17  APPLICATION_TYPE_T19  ...  INCOME_AMT_1-9999  \\\n",
       "0                   0.0                   0.0  ...                0.0   \n",
       "1                   0.0                   0.0  ...                1.0   \n",
       "2                   0.0                   0.0  ...                0.0   \n",
       "3                   0.0                   0.0  ...                0.0   \n",
       "4                   0.0                   0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "encoded_df = pd.concat([numerical_df, encoded_df], axis=1)\n",
    "\n",
    "# Review the Dataframe\n",
    "encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “IS_SUCCESSFUL”. The remaining columns should define the features dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: IS_SUCCESSFUL, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target set y using the IS_SUCCESSFUL column\n",
    "y = encoded_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Display a sample of y\n",
    "y[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  \\\n",
       "0       1     5000                   1.0                   0.0   \n",
       "1       1   108590                   0.0                   0.0   \n",
       "2       1     5000                   0.0                   0.0   \n",
       "3       1     6692                   0.0                   0.0   \n",
       "4       1   142590                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T13  APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T17  APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  ...  \\\n",
       "0                   0.0                   0.0                  0.0  ...   \n",
       "1                   0.0                   0.0                  0.0  ...   \n",
       "2                   0.0                   0.0                  0.0  ...   \n",
       "3                   0.0                   0.0                  0.0  ...   \n",
       "4                   0.0                   0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features set X by selecting all columns but IS_SUCCESSFUL\n",
    "X = encoded_df.drop(columns = ['IS_SUCCESSFUL'])\n",
    "\n",
    "# Review the features DataFrame\n",
    "X[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Split the features and target sets into training and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25719</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25720</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25723</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25724 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS  ASK_AMT  APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  \\\n",
       "0           1     5000                   0.0                   0.0   \n",
       "1           1     5000                   0.0                   0.0   \n",
       "2           1     5000                   0.0                   0.0   \n",
       "3           1     5000                   0.0                   0.0   \n",
       "4           1     5000                   1.0                   0.0   \n",
       "...       ...      ...                   ...                   ...   \n",
       "25719       1     5000                   0.0                   0.0   \n",
       "25720       1     5000                   0.0                   0.0   \n",
       "25721       1     5000                   0.0                   0.0   \n",
       "25722       1     5000                   0.0                   0.0   \n",
       "25723       1     5000                   0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T13  APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "25719                   0.0                   0.0                   0.0   \n",
       "25720                   0.0                   0.0                   0.0   \n",
       "25721                   0.0                   0.0                   0.0   \n",
       "25722                   0.0                   0.0                   0.0   \n",
       "25723                   0.0                   0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T17  APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  ...  \\\n",
       "0                       0.0                   0.0                  0.0  ...   \n",
       "1                       0.0                   0.0                  0.0  ...   \n",
       "2                       0.0                   0.0                  0.0  ...   \n",
       "3                       0.0                   0.0                  0.0  ...   \n",
       "4                       0.0                   0.0                  0.0  ...   \n",
       "...                     ...                   ...                  ...  ...   \n",
       "25719                   0.0                   0.0                  0.0  ...   \n",
       "25720                   0.0                   0.0                  0.0  ...   \n",
       "25721                   0.0                   0.0                  0.0  ...   \n",
       "25722                   0.0                   0.0                  0.0  ...   \n",
       "25723                   0.0                   0.0                  0.0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                    0.0                     0.0                       0.0   \n",
       "1                    0.0                     0.0                       0.0   \n",
       "2                    0.0                     0.0                       0.0   \n",
       "3                    0.0                     0.0                       0.0   \n",
       "4                    0.0                     0.0                       0.0   \n",
       "...                  ...                     ...                       ...   \n",
       "25719                0.0                     0.0                       0.0   \n",
       "25720                0.0                     0.0                       0.0   \n",
       "25721                0.0                     0.0                       0.0   \n",
       "25722                0.0                     0.0                       0.0   \n",
       "25723                0.0                     0.0                       0.0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                     0.0               0.0                     0.0   \n",
       "1                     0.0               0.0                     0.0   \n",
       "2                     0.0               0.0                     0.0   \n",
       "3                     0.0               0.0                     0.0   \n",
       "4                     0.0               0.0                     0.0   \n",
       "...                   ...               ...                     ...   \n",
       "25719                 0.0               0.0                     0.0   \n",
       "25720                 0.0               0.0                     0.0   \n",
       "25721                 0.0               0.0                     0.0   \n",
       "25722                 0.0               0.0                     0.0   \n",
       "25723                 0.0               0.0                     0.0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                  0.0                0.0                       1.0   \n",
       "1                  0.0                0.0                       1.0   \n",
       "2                  0.0                0.0                       1.0   \n",
       "3                  0.0                0.0                       1.0   \n",
       "4                  0.0                0.0                       1.0   \n",
       "...                ...                ...                       ...   \n",
       "25719              0.0                0.0                       1.0   \n",
       "25720              0.0                0.0                       1.0   \n",
       "25721              0.0                0.0                       1.0   \n",
       "25722              0.0                0.0                       1.0   \n",
       "25723              0.0                0.0                       1.0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "...                         ...  \n",
       "25719                       0.0  \n",
       "25720                       0.0  \n",
       "25721                       0.0  \n",
       "25722                       0.0  \n",
       "25723                       0.0  \n",
       "\n",
       "[25724 rows x 116 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(X_train).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Use scikit-learn's `StandardScaler` to scale the features data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T12</th>\n",
       "      <th>APPLICATION_TYPE_T13</th>\n",
       "      <th>APPLICATION_TYPE_T14</th>\n",
       "      <th>APPLICATION_TYPE_T15</th>\n",
       "      <th>APPLICATION_TYPE_T17</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T2</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5052</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25173</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11405</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS  ASK_AMT  APPLICATION_TYPE_T10  APPLICATION_TYPE_T12  \\\n",
       "10679       1     5000                   0.0                   0.0   \n",
       "5052        1     5000                   0.0                   0.0   \n",
       "9990        1     5000                   0.0                   0.0   \n",
       "25173       1     5000                   0.0                   0.0   \n",
       "11405       1     5000                   1.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T13  APPLICATION_TYPE_T14  APPLICATION_TYPE_T15  \\\n",
       "10679                   0.0                   0.0                   0.0   \n",
       "5052                    0.0                   0.0                   0.0   \n",
       "9990                    0.0                   0.0                   0.0   \n",
       "25173                   0.0                   0.0                   0.0   \n",
       "11405                   0.0                   0.0                   0.0   \n",
       "\n",
       "       APPLICATION_TYPE_T17  APPLICATION_TYPE_T19  APPLICATION_TYPE_T2  ...  \\\n",
       "10679                   0.0                   0.0                  0.0  ...   \n",
       "5052                    0.0                   0.0                  0.0  ...   \n",
       "9990                    0.0                   0.0                  0.0  ...   \n",
       "25173                   0.0                   0.0                  0.0  ...   \n",
       "11405                   0.0                   0.0                  0.0  ...   \n",
       "\n",
       "       INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "10679                0.0                     0.0                       0.0   \n",
       "5052                 0.0                     0.0                       0.0   \n",
       "9990                 0.0                     0.0                       0.0   \n",
       "25173                0.0                     0.0                       0.0   \n",
       "11405                0.0                     0.0                       0.0   \n",
       "\n",
       "       INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "10679                 0.0               0.0                     0.0   \n",
       "5052                  0.0               0.0                     0.0   \n",
       "9990                  0.0               0.0                     0.0   \n",
       "25173                 0.0               0.0                     0.0   \n",
       "11405                 0.0               0.0                     0.0   \n",
       "\n",
       "       INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "10679              0.0                0.0                       1.0   \n",
       "5052               0.0                0.0                       1.0   \n",
       "9990               0.0                0.0                       1.0   \n",
       "25173              0.0                0.0                       1.0   \n",
       "11405              0.0                0.0                       1.0   \n",
       "\n",
       "       SPECIAL_CONSIDERATIONS_Y  \n",
       "10679                       0.0  \n",
       "5052                        0.0  \n",
       "9990                        0.0  \n",
       "25173                       0.0  \n",
       "11405                       0.0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Columns: 117 entries, STATUS to SPECIAL_CONSIDERATIONS_Y\n",
      "dtypes: float64(114), int64(3)\n",
      "memory usage: 30.6 MB\n"
     ]
    }
   ],
   "source": [
    "encoded_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compile and Evaluate a Binary Classification Model Using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
    "\n",
    "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = 116\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1 = 40\n",
    "\n",
    "# Review the number hidden nodes in the first layer\n",
    "hidden_nodes_layer1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2 = 20\n",
    "\n",
    "# Review the number hidden nodes in the second layer\n",
    "hidden_nodes_layer2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first hidden layer\n",
    "nn.add(\n",
    "    Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 40)                4680      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,521\n",
      "Trainable params: 5,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the Sequential model summary\n",
    "nn.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 - 2s - loss: 0.6490 - accuracy: 0.6721 - tp: 10286.0000 - tn: 7004.0000 - fp: 4997.0000 - fn: 3437.0000 - precision: 0.6730 - recall: 0.7495 - auc: 0.6958 - val_loss: 0.6093 - val_accuracy: 0.6996 - val_tp: 3582.0000 - val_tn: 2417.0000 - val_fp: 1620.0000 - val_fn: 956.0000 - val_precision: 0.6886 - val_recall: 0.7893 - val_auc: 0.7384 - 2s/epoch - 70ms/step\n",
      "Epoch 2/20\n",
      "26/26 - 0s - loss: 0.5898 - accuracy: 0.7115 - tp: 10673.0000 - tn: 7629.0000 - fp: 4372.0000 - fn: 3050.0000 - precision: 0.7094 - recall: 0.7777 - auc: 0.7543 - val_loss: 0.5802 - val_accuracy: 0.7191 - val_tp: 3580.0000 - val_tn: 2586.0000 - val_fp: 1451.0000 - val_fn: 958.0000 - val_precision: 0.7116 - val_recall: 0.7889 - val_auc: 0.7649 - 126ms/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "26/26 - 0s - loss: 0.5689 - accuracy: 0.7227 - tp: 10650.0000 - tn: 7942.0000 - fp: 4059.0000 - fn: 3073.0000 - precision: 0.7240 - recall: 0.7761 - auc: 0.7732 - val_loss: 0.5699 - val_accuracy: 0.7226 - val_tp: 3575.0000 - val_tn: 2621.0000 - val_fp: 1416.0000 - val_fn: 963.0000 - val_precision: 0.7163 - val_recall: 0.7878 - val_auc: 0.7733 - 125ms/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "26/26 - 0s - loss: 0.5599 - accuracy: 0.7248 - tp: 10669.0000 - tn: 7976.0000 - fp: 4025.0000 - fn: 3054.0000 - precision: 0.7261 - recall: 0.7775 - auc: 0.7795 - val_loss: 0.5646 - val_accuracy: 0.7273 - val_tp: 3623.0000 - val_tn: 2614.0000 - val_fp: 1423.0000 - val_fn: 915.0000 - val_precision: 0.7180 - val_recall: 0.7984 - val_auc: 0.7780 - 128ms/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "26/26 - 0s - loss: 0.5551 - accuracy: 0.7302 - tp: 10749.0000 - tn: 8034.0000 - fp: 3967.0000 - fn: 2974.0000 - precision: 0.7304 - recall: 0.7833 - auc: 0.7829 - val_loss: 0.5620 - val_accuracy: 0.7307 - val_tp: 3622.0000 - val_tn: 2644.0000 - val_fp: 1393.0000 - val_fn: 916.0000 - val_precision: 0.7222 - val_recall: 0.7981 - val_auc: 0.7800 - 125ms/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "26/26 - 0s - loss: 0.5517 - accuracy: 0.7322 - tp: 10743.0000 - tn: 8091.0000 - fp: 3910.0000 - fn: 2980.0000 - precision: 0.7332 - recall: 0.7828 - auc: 0.7857 - val_loss: 0.5602 - val_accuracy: 0.7308 - val_tp: 3624.0000 - val_tn: 2643.0000 - val_fp: 1394.0000 - val_fn: 914.0000 - val_precision: 0.7222 - val_recall: 0.7986 - val_auc: 0.7813 - 125ms/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "26/26 - 0s - loss: 0.5497 - accuracy: 0.7325 - tp: 10764.0000 - tn: 8078.0000 - fp: 3923.0000 - fn: 2959.0000 - precision: 0.7329 - recall: 0.7844 - auc: 0.7867 - val_loss: 0.5589 - val_accuracy: 0.7314 - val_tp: 3608.0000 - val_tn: 2664.0000 - val_fp: 1373.0000 - val_fn: 930.0000 - val_precision: 0.7244 - val_recall: 0.7951 - val_auc: 0.7817 - 130ms/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "26/26 - 0s - loss: 0.5481 - accuracy: 0.7324 - tp: 10755.0000 - tn: 8084.0000 - fp: 3917.0000 - fn: 2968.0000 - precision: 0.7330 - recall: 0.7837 - auc: 0.7885 - val_loss: 0.5579 - val_accuracy: 0.7304 - val_tp: 3598.0000 - val_tn: 2665.0000 - val_fp: 1372.0000 - val_fn: 940.0000 - val_precision: 0.7239 - val_recall: 0.7929 - val_auc: 0.7830 - 139ms/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "26/26 - 0s - loss: 0.5469 - accuracy: 0.7336 - tp: 10786.0000 - tn: 8085.0000 - fp: 3916.0000 - fn: 2937.0000 - precision: 0.7336 - recall: 0.7860 - auc: 0.7899 - val_loss: 0.5575 - val_accuracy: 0.7297 - val_tp: 3609.0000 - val_tn: 2648.0000 - val_fp: 1389.0000 - val_fn: 929.0000 - val_precision: 0.7221 - val_recall: 0.7953 - val_auc: 0.7833 - 129ms/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "26/26 - 0s - loss: 0.5460 - accuracy: 0.7335 - tp: 10777.0000 - tn: 8092.0000 - fp: 3909.0000 - fn: 2946.0000 - precision: 0.7338 - recall: 0.7853 - auc: 0.7901 - val_loss: 0.5572 - val_accuracy: 0.7307 - val_tp: 3625.0000 - val_tn: 2641.0000 - val_fp: 1396.0000 - val_fn: 913.0000 - val_precision: 0.7220 - val_recall: 0.7988 - val_auc: 0.7844 - 127ms/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "26/26 - 0s - loss: 0.5453 - accuracy: 0.7343 - tp: 10857.0000 - tn: 8033.0000 - fp: 3968.0000 - fn: 2866.0000 - precision: 0.7323 - recall: 0.7912 - auc: 0.7906 - val_loss: 0.5572 - val_accuracy: 0.7291 - val_tp: 3653.0000 - val_tn: 2599.0000 - val_fp: 1438.0000 - val_fn: 885.0000 - val_precision: 0.7175 - val_recall: 0.8050 - val_auc: 0.7843 - 128ms/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "26/26 - 0s - loss: 0.5445 - accuracy: 0.7354 - tp: 10881.0000 - tn: 8036.0000 - fp: 3965.0000 - fn: 2842.0000 - precision: 0.7329 - recall: 0.7929 - auc: 0.7913 - val_loss: 0.5566 - val_accuracy: 0.7293 - val_tp: 3602.0000 - val_tn: 2652.0000 - val_fp: 1385.0000 - val_fn: 936.0000 - val_precision: 0.7223 - val_recall: 0.7937 - val_auc: 0.7849 - 123ms/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "26/26 - 0s - loss: 0.5439 - accuracy: 0.7351 - tp: 10835.0000 - tn: 8074.0000 - fp: 3927.0000 - fn: 2888.0000 - precision: 0.7340 - recall: 0.7896 - auc: 0.7922 - val_loss: 0.5576 - val_accuracy: 0.7300 - val_tp: 3671.0000 - val_tn: 2589.0000 - val_fp: 1448.0000 - val_fn: 867.0000 - val_precision: 0.7171 - val_recall: 0.8089 - val_auc: 0.7849 - 129ms/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "26/26 - 0s - loss: 0.5432 - accuracy: 0.7349 - tp: 10890.0000 - tn: 8014.0000 - fp: 3987.0000 - fn: 2833.0000 - precision: 0.7320 - recall: 0.7936 - auc: 0.7926 - val_loss: 0.5569 - val_accuracy: 0.7289 - val_tp: 3651.0000 - val_tn: 2599.0000 - val_fp: 1438.0000 - val_fn: 887.0000 - val_precision: 0.7174 - val_recall: 0.8045 - val_auc: 0.7847 - 129ms/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "26/26 - 0s - loss: 0.5434 - accuracy: 0.7343 - tp: 10845.0000 - tn: 8045.0000 - fp: 3956.0000 - fn: 2878.0000 - precision: 0.7327 - recall: 0.7903 - auc: 0.7925 - val_loss: 0.5568 - val_accuracy: 0.7298 - val_tp: 3661.0000 - val_tn: 2597.0000 - val_fp: 1440.0000 - val_fn: 877.0000 - val_precision: 0.7177 - val_recall: 0.8067 - val_auc: 0.7852 - 131ms/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "26/26 - 0s - loss: 0.5427 - accuracy: 0.7353 - tp: 10915.0000 - tn: 8000.0000 - fp: 4001.0000 - fn: 2808.0000 - precision: 0.7318 - recall: 0.7954 - auc: 0.7929 - val_loss: 0.5567 - val_accuracy: 0.7297 - val_tp: 3643.0000 - val_tn: 2614.0000 - val_fp: 1423.0000 - val_fn: 895.0000 - val_precision: 0.7191 - val_recall: 0.8028 - val_auc: 0.7850 - 135ms/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "26/26 - 0s - loss: 0.5422 - accuracy: 0.7356 - tp: 10910.0000 - tn: 8013.0000 - fp: 3988.0000 - fn: 2813.0000 - precision: 0.7323 - recall: 0.7950 - auc: 0.7934 - val_loss: 0.5567 - val_accuracy: 0.7286 - val_tp: 3636.0000 - val_tn: 2612.0000 - val_fp: 1425.0000 - val_fn: 902.0000 - val_precision: 0.7184 - val_recall: 0.8012 - val_auc: 0.7856 - 127ms/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "26/26 - 0s - loss: 0.5418 - accuracy: 0.7343 - tp: 10840.0000 - tn: 8048.0000 - fp: 3953.0000 - fn: 2883.0000 - precision: 0.7328 - recall: 0.7899 - auc: 0.7938 - val_loss: 0.5568 - val_accuracy: 0.7285 - val_tp: 3649.0000 - val_tn: 2598.0000 - val_fp: 1439.0000 - val_fn: 889.0000 - val_precision: 0.7172 - val_recall: 0.8041 - val_auc: 0.7852 - 126ms/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "26/26 - 0s - loss: 0.5417 - accuracy: 0.7352 - tp: 10882.0000 - tn: 8031.0000 - fp: 3970.0000 - fn: 2841.0000 - precision: 0.7327 - recall: 0.7930 - auc: 0.7934 - val_loss: 0.5564 - val_accuracy: 0.7293 - val_tp: 3613.0000 - val_tn: 2641.0000 - val_fp: 1396.0000 - val_fn: 925.0000 - val_precision: 0.7213 - val_recall: 0.7962 - val_auc: 0.7857 - 130ms/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "26/26 - 0s - loss: 0.5410 - accuracy: 0.7354 - tp: 10903.0000 - tn: 8014.0000 - fp: 3987.0000 - fn: 2820.0000 - precision: 0.7322 - recall: 0.7945 - auc: 0.7946 - val_loss: 0.5564 - val_accuracy: 0.7297 - val_tp: 3612.0000 - val_tn: 2645.0000 - val_fp: 1392.0000 - val_fn: 926.0000 - val_precision: 0.7218 - val_recall: 0.7959 - val_auc: 0.7858 - 182ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "batch_size = 1000\n",
    "epochs = 20\n",
    "\n",
    "t_history = nn.fit(X_train_scaled,\n",
    "    y_train,\n",
    "    validation_data=(X_test_scaled, y_test),               \n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model using the test data to determine the model’s loss and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7297 - tp: 3612.0000 - tn: 2645.0000 - fp: 1392.0000 - fn: 926.0000 - precision: 0.7218 - recall: 0.7959 - auc: 0.7858\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18732\\1616559286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Display the model loss and accuracy results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loss: {model_loss}, Accuracy: {model_accuracy}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_L_auc = pd.DataFrame(t_history.history, index=range(1,len(t_history.history['loss']) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_L_auc.plot(y='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Save and export your model to an HDF5 file, and name the file `AlphabetSoup.h5`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's file path  \"C:\\Users\\nasjo\\Documents\\Analysis\"\n",
    "file_path = Path(\"Users/nasjo/Documents/Analysis/13_Venture Funding with Deep/AlphabetSoup.h5\")\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn.save(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optimize the neural network model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define at least three new deep neural network models (resulting in the original plus 3 optimization attempts). With each, try to improve on your first model’s predictive accuracy.\n",
    "\n",
    "> **Rewind** Recall that perfect accuracy has a value of 1, so accuracy improves as its value moves closer to 1. To optimize your model for a predictive accuracy as close to 1 as possible, you can use any or all of the following techniques:\n",
    ">\n",
    "> * Adjust the input data by dropping different features columns to ensure that no variables or outliers confuse the model.\n",
    ">\n",
    "> * Add more neurons (nodes) to a hidden layer.\n",
    ">\n",
    "> * Add more hidden layers.\n",
    ">\n",
    "> * Use different activation functions for the hidden layers.\n",
    ">\n",
    "> * Add to or reduce the number of epochs in the training regimen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['T10', 'T12', 'T13', 'T14', 'T15', 'T17', 'T19', 'T2', 'T25',\n",
       "        'T29', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9'], dtype=object),\n",
       " array(['CompanySponsored', 'Family/Parent', 'Independent', 'National',\n",
       "        'Other', 'Regional'], dtype=object),\n",
       " array(['C0', 'C1000', 'C1200', 'C1230', 'C1234', 'C1235', 'C1236',\n",
       "        'C1237', 'C1238', 'C1240', 'C1245', 'C1246', 'C1248', 'C1250',\n",
       "        'C1256', 'C1257', 'C1260', 'C1267', 'C1270', 'C1278', 'C1280',\n",
       "        'C1283', 'C1300', 'C1370', 'C1400', 'C1500', 'C1570', 'C1580',\n",
       "        'C1600', 'C1700', 'C1720', 'C1728', 'C1732', 'C1800', 'C1820',\n",
       "        'C1900', 'C2000', 'C2100', 'C2150', 'C2170', 'C2190', 'C2300',\n",
       "        'C2380', 'C2400', 'C2500', 'C2561', 'C2570', 'C2600', 'C2700',\n",
       "        'C2710', 'C2800', 'C3000', 'C3200', 'C3700', 'C4000', 'C4100',\n",
       "        'C4120', 'C4200', 'C4500', 'C5000', 'C5200', 'C6000', 'C6100',\n",
       "        'C7000', 'C7100', 'C7120', 'C7200', 'C7210', 'C8000', 'C8200',\n",
       "        'C8210'], dtype=object),\n",
       " array(['CommunityServ', 'Heathcare', 'Other', 'Preservation',\n",
       "        'ProductDev'], dtype=object),\n",
       " array(['Association', 'Co-operative', 'Corporation', 'Trust'],\n",
       "       dtype=object),\n",
       " array(['0', '1-9999', '10000-24999', '100000-499999', '10M-50M', '1M-5M',\n",
       "        '25000-99999', '50M+', '5M-10M'], dtype=object),\n",
       " array(['N', 'Y'], dtype=object)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A1 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A1 = 50\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn_A1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 50)                5850      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,901\n",
      "Trainable params: 5,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First hidden layer\n",
    "nn_A1.add(\n",
    "    Dense(units=hidden_nodes_layer1_A1, input_dim=number_input_features, activation=\"tanh\")\n",
    ")\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn_A1.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_A1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A1.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"categorical_crossentropy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 - 2s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 2s/epoch - 94ms/step\n",
      "Epoch 2/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 108ms/epoch - 6ms/step\n",
      "Epoch 3/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 109ms/epoch - 6ms/step\n",
      "Epoch 4/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 110ms/epoch - 6ms/step\n",
      "Epoch 5/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 109ms/epoch - 6ms/step\n",
      "Epoch 6/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 105ms/epoch - 6ms/step\n",
      "Epoch 7/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 111ms/epoch - 6ms/step\n",
      "Epoch 8/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 114ms/epoch - 6ms/step\n",
      "Epoch 9/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 110ms/epoch - 6ms/step\n",
      "Epoch 10/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 115ms/epoch - 6ms/step\n",
      "Epoch 11/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 119ms/epoch - 7ms/step\n",
      "Epoch 12/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 114ms/epoch - 6ms/step\n",
      "Epoch 13/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 110ms/epoch - 6ms/step\n",
      "Epoch 14/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 111ms/epoch - 6ms/step\n",
      "Epoch 15/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 110ms/epoch - 6ms/step\n",
      "Epoch 16/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 130ms/epoch - 7ms/step\n",
      "Epoch 17/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 112ms/epoch - 6ms/step\n",
      "Epoch 18/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 114ms/epoch - 6ms/step\n",
      "Epoch 19/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 117ms/epoch - 6ms/step\n",
      "Epoch 20/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 118ms/epoch - 7ms/step\n",
      "Epoch 21/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 109ms/epoch - 6ms/step\n",
      "Epoch 22/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 112ms/epoch - 6ms/step\n",
      "Epoch 23/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 175ms/epoch - 10ms/step\n",
      "Epoch 24/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 125ms/epoch - 7ms/step\n",
      "Epoch 25/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 115ms/epoch - 6ms/step\n",
      "Epoch 26/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 112ms/epoch - 6ms/step\n",
      "Epoch 27/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 116ms/epoch - 6ms/step\n",
      "Epoch 28/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 113ms/epoch - 6ms/step\n",
      "Epoch 29/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 110ms/epoch - 6ms/step\n",
      "Epoch 30/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 103ms/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "batch_size = 1500\n",
    "epochs = 30\n",
    "\n",
    "A1_t_history = nn_A1.fit(X_train_scaled,\n",
    "    y_train,\n",
    "    validation_data=(X_test_scaled, y_test),               \n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 4538.0000 - tn: 0.0000e+00 - fp: 4037.0000 - fn: 0.0000e+00 - precision: 0.5292 - recall: 1.0000 - auc: 0.5000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18732\\3227217696.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_loss1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_accuracy1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_A1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loss: {model_loss1}, Accuracy: {model_accuracy1}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model_loss1, model_accuracy1 = nn_A1.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "print(f\"Loss: {model_loss1}, Accuracy: {model_accuracy1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'tp', 'tn', 'fp', 'fn', 'precision', 'recall', 'auc', 'val_loss', 'val_accuracy', 'val_tp', 'val_tn', 'val_fp', 'val_fn', 'val_precision', 'val_recall', 'val_auc'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history = t_history.history\n",
    "model_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6721349954605103,\n",
       " 0.711475670337677,\n",
       " 0.7227491736412048,\n",
       " 0.7248095273971558,\n",
       " 0.73017418384552,\n",
       " 0.7321567535400391,\n",
       " 0.7324677109718323,\n",
       " 0.7323511242866516,\n",
       " 0.733595073223114,\n",
       " 0.7335173487663269,\n",
       " 0.7343336939811707,\n",
       " 0.7353832721710205,\n",
       " 0.7350723147392273,\n",
       " 0.7348779439926147,\n",
       " 0.7343336939811707,\n",
       " 0.7353055477142334,\n",
       " 0.7356165647506714,\n",
       " 0.7342559695243835,\n",
       " 0.7352278232574463,\n",
       " 0.7353832721710205]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A2 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A2 = 30\n",
    "\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn_A2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 30)                3510      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,541\n",
      "Trainable params: 3,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First hidden layer\n",
    "nn_A2.add(\n",
    "    Dense(units=hidden_nodes_layer1_A2, input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn_A2.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_A2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_A2.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "804/804 [==============================] - 2s 1ms/step - loss: 0.5883 - mse: 0.5883\n",
      "Epoch 2/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2747 - mse: 0.2747\n",
      "Epoch 3/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2219 - mse: 0.2219\n",
      "Epoch 4/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2176 - mse: 0.2176\n",
      "Epoch 5/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2227 - mse: 0.2227\n",
      "Epoch 6/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2286 - mse: 0.2286\n",
      "Epoch 7/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2230 - mse: 0.2230\n",
      "Epoch 8/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2154 - mse: 0.2154\n",
      "Epoch 9/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2104 - mse: 0.2104\n",
      "Epoch 10/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2041 - mse: 0.2041\n",
      "Epoch 11/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2093 - mse: 0.2093\n",
      "Epoch 12/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2086 - mse: 0.2086\n",
      "Epoch 13/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.2020 - mse: 0.2020\n",
      "Epoch 14/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1950 - mse: 0.1950\n",
      "Epoch 15/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1965 - mse: 0.1965\n",
      "Epoch 16/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1931 - mse: 0.1931\n",
      "Epoch 17/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1940 - mse: 0.1940\n",
      "Epoch 18/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1935 - mse: 0.1935\n",
      "Epoch 19/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1902 - mse: 0.1902\n",
      "Epoch 20/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1910 - mse: 0.1910\n",
      "Epoch 21/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1909 - mse: 0.1909\n",
      "Epoch 22/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1908 - mse: 0.1908\n",
      "Epoch 23/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1870 - mse: 0.1870\n",
      "Epoch 24/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 25/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1860 - mse: 0.1860\n",
      "Epoch 26/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1867 - mse: 0.1867\n",
      "Epoch 27/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 28/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1857 - mse: 0.1857\n",
      "Epoch 29/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1852 - mse: 0.1852\n",
      "Epoch 30/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1872 - mse: 0.1872\n",
      "Epoch 31/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1862 - mse: 0.1862\n",
      "Epoch 32/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1844 - mse: 0.1844\n",
      "Epoch 33/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1844 - mse: 0.1844\n",
      "Epoch 34/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 35/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1850 - mse: 0.1850\n",
      "Epoch 36/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1856 - mse: 0.1856\n",
      "Epoch 37/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1844 - mse: 0.1844\n",
      "Epoch 38/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1844 - mse: 0.1844\n",
      "Epoch 39/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1841 - mse: 0.1841\n",
      "Epoch 40/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1844 - mse: 0.1844\n",
      "Epoch 41/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1841 - mse: 0.1841\n",
      "Epoch 42/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1840 - mse: 0.1840\n",
      "Epoch 43/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1842 - mse: 0.1842\n",
      "Epoch 44/70\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.1834 - mse: 0.1834\n",
      "Epoch 45/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1839 - mse: 0.1839\n",
      "Epoch 46/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1840 - mse: 0.1840\n",
      "Epoch 47/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1843 - mse: 0.1843\n",
      "Epoch 48/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1836 - mse: 0.1836\n",
      "Epoch 49/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1839 - mse: 0.1839\n",
      "Epoch 50/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1835 - mse: 0.1835\n",
      "Epoch 51/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1830 - mse: 0.1830\n",
      "Epoch 52/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1836 - mse: 0.1836\n",
      "Epoch 53/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1840 - mse: 0.1840\n",
      "Epoch 54/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1837 - mse: 0.1837\n",
      "Epoch 55/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1834 - mse: 0.1834\n",
      "Epoch 56/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1833 - mse: 0.1833\n",
      "Epoch 57/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1830 - mse: 0.1830\n",
      "Epoch 58/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1827 - mse: 0.1827\n",
      "Epoch 59/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1836 - mse: 0.1836\n",
      "Epoch 60/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1835 - mse: 0.1835\n",
      "Epoch 61/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1825 - mse: 0.1825\n",
      "Epoch 62/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1824 - mse: 0.1824\n",
      "Epoch 63/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1831 - mse: 0.1831\n",
      "Epoch 64/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1823 - mse: 0.1823\n",
      "Epoch 65/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1832 - mse: 0.1832\n",
      "Epoch 66/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1826 - mse: 0.1826\n",
      "Epoch 67/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1825 - mse: 0.1825\n",
      "Epoch 68/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1829 - mse: 0.1829\n",
      "Epoch 69/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1828 - mse: 0.1828\n",
      "Epoch 70/70\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.1826 - mse: 0.1826\n",
      "Epoch 1/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 149ms/epoch - 8ms/step\n",
      "Epoch 2/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 110ms/epoch - 6ms/step\n",
      "Epoch 3/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 103ms/epoch - 6ms/step\n",
      "Epoch 4/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 103ms/epoch - 6ms/step\n",
      "Epoch 5/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 112ms/epoch - 6ms/step\n",
      "Epoch 6/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 103ms/epoch - 6ms/step\n",
      "Epoch 7/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 105ms/epoch - 6ms/step\n",
      "Epoch 8/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 102ms/epoch - 6ms/step\n",
      "Epoch 9/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 103ms/epoch - 6ms/step\n",
      "Epoch 10/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 108ms/epoch - 6ms/step\n",
      "Epoch 11/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 107ms/epoch - 6ms/step\n",
      "Epoch 12/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 105ms/epoch - 6ms/step\n",
      "Epoch 13/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 104ms/epoch - 6ms/step\n",
      "Epoch 14/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 115ms/epoch - 6ms/step\n",
      "Epoch 15/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 103ms/epoch - 6ms/step\n",
      "Epoch 16/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 106ms/epoch - 6ms/step\n",
      "Epoch 17/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 105ms/epoch - 6ms/step\n",
      "Epoch 18/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 105ms/epoch - 6ms/step\n",
      "Epoch 19/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 103ms/epoch - 6ms/step\n",
      "Epoch 20/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 106ms/epoch - 6ms/step\n",
      "Epoch 21/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 119ms/epoch - 7ms/step\n",
      "Epoch 22/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 110ms/epoch - 6ms/step\n",
      "Epoch 23/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 113ms/epoch - 6ms/step\n",
      "Epoch 24/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 108ms/epoch - 6ms/step\n",
      "Epoch 25/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 108ms/epoch - 6ms/step\n",
      "Epoch 26/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 111ms/epoch - 6ms/step\n",
      "Epoch 27/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 113ms/epoch - 6ms/step\n",
      "Epoch 28/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 107ms/epoch - 6ms/step\n",
      "Epoch 29/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 109ms/epoch - 6ms/step\n",
      "Epoch 30/30\n",
      "18/18 - 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 13723.0000 - tn: 0.0000e+00 - fp: 12001.0000 - fn: 0.0000e+00 - precision: 0.5335 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.0000e+00 - val_categorical_crossentropy: 0.0000e+00 - val_tp: 4538.0000 - val_tn: 0.0000e+00 - val_fp: 4037.0000 - val_fn: 0.0000e+00 - val_precision: 0.5292 - val_recall: 1.0000 - val_auc: 0.5000 - 108ms/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "deep_mse_model = nn_A2.fit(X_train_scaled, y_train, epochs=70)\n",
    "\n",
    "A1_t_history = nn_A1.fit(X_train_scaled,\n",
    "    y_train,\n",
    "    validation_data=(X_test_scaled, y_test),               \n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.1845 - mse: 0.1845 - 385ms/epoch - 1ms/step\n",
      "Loss: 0.18454323709011078, Accuracy: 0.18454323709011078\n"
     ]
    }
   ],
   "source": [
    "model_loss2, model_accuracy2 = nn_A2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "print(f\"Loss: {model_loss2}, Accuracy: {model_accuracy2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: After finishing your models, display the accuracy scores achieved by each model, and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Results\n",
      "268/268 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7297 - tp: 3612.0000 - tn: 2645.0000 - fp: 1392.0000 - fn: 926.0000 - precision: 0.7218 - recall: 0.7959 - auc: 0.7858\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18732\\2392695924.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Display the model loss and accuracy results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "print(\"Original Model Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 1 Results\n",
      "268/268 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00 - tp: 4538.0000 - tn: 0.0000e+00 - fp: 4037.0000 - fn: 0.0000e+00 - precision: 0.5292 - recall: 1.0000 - auc: 0.5000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18732\\26473351.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel_loss1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_accuracy1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_A1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Display the model loss and accuracy results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 1 Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss1, model_accuracy1 = nn_A1.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss1}, Accuracy: {model_accuracy1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 2 Results\n",
      "268/268 [==============================] - 0s 1ms/step - loss: 0.1845 - mse: 0.1845\n",
      "Loss: 0.18454323709011078, Accuracy: 0.18454323709011078\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 2 Results\")\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss2, model_accuracy2 = nn_A2.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss2}, Accuracy: {model_accuracy2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Save each of your alternative models as an HDF5 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the first alternative model\n",
    "file_path = Path(\"Users/nasjo/Documents/Analysis/13_Venture Funding with Deep/AlphabetSoup_A1.h5\")\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn_A1.save(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the second alternative model\n",
    "file_path = Path(\"Users/nasjo/Documents/Analysis/13_Venture Funding with Deep/AlphabetSoup_A2.h5\")\n",
    "\n",
    "# Export your model to a HDF5 file\n",
    "nn_A2.save(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
